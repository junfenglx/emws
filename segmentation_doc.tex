\documentclass[]{article}
\usepackage{nips15submit_e,times}

\usepackage{hyperref}
\usepackage{url}


% for math
\usepackage{mathtools}

% for pictures
\usepackage{graphicx}

% datetime
\usepackage{datetime}


% chinese fonts
\usepackage{my_arch_ctex_fonts}

% for code
\usepackage{minted}


%opening
\title{中文分词实验过程}


\author{
	Junfeng~Hu\thanks{ \url{http://junfeng-hu.github.io/}} \\
	School of Computer Science\\
	Fudan University\\
	No.825, Zhangheng Road, Shanghai \\
	\texttt{15210240075@fudan.edu.cn} \\
}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}

\maketitle

% \begin{abstract}

% \end{abstract}

\section{Embedding Matching}

\small{
	写于\today \currenttime
}

双向具体实现过程

\subsection{使用右边字状态}
使用右边两个字的状态。

由于训练时从左向右扫描汉字，所以右边两个字的当前 label 无法预先
知道，因此需要寻找一种机制来获取右边两个字的 label。

尝试了两种方案：
\begin{enumerate}
	\item train时，左边状态使用当前迭代，右边使用gold standard labels
	\item train时，左右全部使用gold standard labels，
	    即使用use\_gold=1开启该参数
\end{enumerate}

测试时，由于并不知道gold standard labels，
使用多次迭代来计算test sentences labels，初始时设置所有labels为1, 表示未分词，
经过多次迭代，得到test sentences 的最终labels。代码片段如下：

\renewcommand\listingscaption{Code}
\begin{listing}[H]
\begin{minted}[frame=single, label=iterate greedy predict]{python}
# initialize states vector
states = np.ones(len(sentence) + 2, dtype=np.int8)
states[0] = 0
states[-1] = 0
states[-2] = 0
if self.no_right_action_feature:
    do_greedy_predict()
else:
    for _ in range(self.iter):
        do_greedy_predict()
\end{minted}
\caption{iterate greedy predict}
\end{listing}

第一种训练方案，测试score达到0.949, 其在第5次迭代后就达到了该水平。

第二种训练方案，测试score达到0.948。

而当使用已有模型对test的输出的labels作为右边两字的labels时(已有模型的score为0.95)，
两种训练方式score都能达到0.951。这和整合两个模型取平均概率的score是一样的。



\end{document}
